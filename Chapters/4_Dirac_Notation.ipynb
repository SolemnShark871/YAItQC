{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Dirac Notation\n",
    "\n",
    "\n",
    "\"*The measure of greatness in a scientific idea is the extent to which it stimulates new thought and opens up new lines of research*\"- Paul Dirac\n",
    "\n",
    "This chapter explains a bit of the framework for quantum computing using the maths from the last chapter. It's like learning the language of quantum computing, first the grammar was introduced in chapter 3, now we are defining the words.  \n",
    "\n",
    "## 4.1 Information inside a computer\n",
    "\n",
    "When using a computer every day, it's important to be able to extract useful information from the computer. For instance, reading emails requires being able to access the information in your inbox. \n",
    "\n",
    "Unlike reading emails, quantum computing works at the lowest level of the system. It would be like directly accessing the bits in a classical computer. Instead of working with bits, quantum computing works with qubits. To do anything at all with qubits, it's important to describe what state they're in. The state of a qubit is described by something known as a ket. \n",
    "\n",
    "\n",
    "### 4.1.1 How to describe qubits?\n",
    "\n",
    "\n",
    "How do we describe the state of our qubits? It is easy to think this would require a very complicated mechanism. For us, it is as simple as a column vector! The state of our quantum computer can be described with a __column vector known as a ket__. Because it is a state represented by a vector, we call this the __state vector__. Usually, the state of our quantum computer is given by the ket $\\ket{\\psi}$.\n",
    "\n",
    "The coins still work as an example for the state vector. If the coin is heads up we can use the ket $\\ket{h}$, if it's tails up it is $\\ket{t}$. When the coin is spinning in the air, the superposition state (see section 1.3), this state can be represented by the state $\\ket{\\psi}$: \n",
    "\n",
    "$$\n",
    "\\ket{\\psi} = \\frac{1}{\\sqrt{2}}(\\ket{h} + \\ket{t})\n",
    "$$\n",
    "\n",
    "Since the coin has a $\\frac{1}{2}$ probability of being in either heads or tails, you might have expected to see $\\frac{1}{2}$ instead of $\\frac{1}{\\sqrt{2}}$. The reason for this is that in quantum mechanics, a state is described with an amplitude (the number outside the ket) proportional to the square root of the probability. \n",
    "\n",
    "We can write out our kets as the simplest column vectors\n",
    "\n",
    "$$\n",
    "\\ket{h} = \n",
    "\n",
    "\\begin{bmatrix}\n",
    "1 \\\\ 0\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Similarly, the tails side up can be represented by the ket\n",
    "\n",
    "$$\n",
    "\\ket{t} = \n",
    "\n",
    "\\begin{bmatrix}\n",
    "0 \\\\ 1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "This allows $\\ket{\\psi} $ to be expanded as \n",
    "\n",
    "$$\n",
    "\\ket{\\psi} = \\frac{1}{\\sqrt{2}}\\left(\\begin{bmatrix}\n",
    "1 \\\\ 0\n",
    "\\end{bmatrix}+ \\begin{bmatrix}\n",
    "0 \\\\ 1\n",
    "\\end{bmatrix}\\right)\n",
    "$$\n",
    "\n",
    "By adding the corresponding elements of each vector, this can be simplified to\n",
    "\n",
    "$$ \\ket{\\psi} = \\frac{1}{\\sqrt{2}}\\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix} = \\ket{+}$$\n",
    "\n",
    "> This superposition state has its own symbol, $\\ket{+}$.\n",
    "\n",
    "Instead, if there were a biased coin which had a probability of heads given by $P$, we would have a different state. The probability amplitude for $H$ is $\\sqrt{P}$. The probability of getting tails would be $ P(T) = 1 - P(H)$ which gives $P(T) = 1 -P$. So our probability amplitude for $T$ is $\\sqrt{1 - P}$. The state of our coin is then \n",
    "\n",
    "$$\n",
    "\\ket{\\psi} = \\sqrt{P}\\ket{h} + \\sqrt{1-P}\\ket{t}\n",
    "$$\n",
    "\n",
    "We can write this as a column vector as\n",
    "\n",
    "$$\n",
    "\\ket{\\psi} = \\begin{bmatrix}\n",
    "\\sqrt{P} \\\\ \\sqrt{1-P}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "> ### Exercise 4.1 \n",
    ">\n",
    ">Imagine a biased coin which is three times more likely to land on tails than on heads. Write down the corresponding state vector for such a coin.\n",
    "\n",
    "\n",
    "### 4.1.2 How to describe the qubits \n",
    "\n",
    "In general, our quantum computer can take a lot more than 2 possible outcomes. Thankfully we can just add a row to our column vector for every possible outcome. So we can describe our state in terms of each possible outcomes it can take. Our quantum computer can output any number up to some maximum.  We can write the state of any quantum computer in terms of all the possible states (numbers) we can get from it\n",
    "\n",
    "$$\n",
    "\\ket{\\psi} = \\sum_{i = 0}^{N-1} c_i \\ket{i}\n",
    "$$\n",
    "\n",
    "Where the index $i$ indicates a possible state we can observe the quantum system in. There are $N$ such possible states. Each state has a probability of being measured given by $|c_i|^2$  with $c_i$ being the probability amplitude. \n",
    "\n",
    "Writing this as a state vector gives us \n",
    "\n",
    "$$\n",
    "\\ket{\\psi} = \\begin{bmatrix} c_0 \\\\ c_1 \\\\ c_2 \\\\ \\vdots \\\\ c_{N-2} \\\\ c_{N-1} \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "A little note here: to model the state of a quantum computer requires keeping track of $N$ complex numbers. That doesn't seem too bad.  But for $n$ qubits we have $N = 2^n$ complex numbers to keep track of. Just 20 qubits would have more than a million complex amplitudes to keep track of! Adding 1 more qubit to get 21 qubits gives us more than 2 million complex amplitudes. \n",
    "\n",
    "In the same way, we can get the coin bras. The $\\bra{h}$ is the same as the ket $\\ket{h} = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}$ but a row vector where the imaginary part of the complex numbers are all multiplied by $-1$. Since there are no imaginary numbers in $\\ket{h}$, the bra $\\bra{h}$ is just the transpose of the column vector as\n",
    "\n",
    "$$\n",
    "\\bra{h} = (\\ket{h}^*)^T = \\begin{bmatrix} 1 & 0 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Just as with the column vector, we can write a general expression for any bra\n",
    "\n",
    "$$\n",
    "\\bra{\\psi} = \\begin{bmatrix} c_0^* & c_1^* & c_2^* & \\dots & c_{N-2}^* & c_{N-1}^* \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "## 4.2 Probability of measurement\n",
    "\n",
    "One of the most important features of quantum computing is measurement. Whenever we do a quantum computation, we change the state of the qubits. The strange thing is that we never actually see the state itself! \n",
    "\n",
    "In the example with the coins, we never see two coins with opposite sides up. The superposition can't be observed directly. Instead, we perform a measurement on the qubits to get some information out of them. The measurement has outcomes with different probabilities, described by the state vector. It's like the lift analogy in Chapter 1, the lift is never observed between two floors, we only see it at the floors. We also don't observe part of the lift on one floor and part of the lift on another floor. Something has gone terribly wrong if the lift is split across multiple floors!\n",
    "\n",
    "For the coins, one may wish to know the probability of flipping the coin and getting heads or tails up. With Dirac notation, the probability of an outcome (heads up) can be calculated using the inner product (see section 3.2.4 for a refresher on the inner product).\n",
    "\n",
    "### 4.2.1 Probabilities come from the inner product\n",
    "\n",
    "Using the coin example, the probability of the coin ending up in the heads state $\\ket{h}$ can be calculated as\n",
    "\n",
    "$$ P(H) = |\\braket{H|\\psi}|^2  $$\n",
    "\n",
    "The state we want to measure $\\ket{h}$ is always on the left (in a bra) and the state we have, $\\psi$ is always on the right in a ket.\n",
    "\n",
    "First we do the inner product $\\braket{H|\\psi}$\n",
    "\n",
    "$$\\braket{H|\\psi} = \\frac{1}{\\sqrt{2}}\\begin{bmatrix} 1 & 0 \\end{bmatrix} \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}$$\n",
    "\n",
    "$$ = \\frac{1}{\\sqrt{2}} (1 + 0 ) = \\frac{1}{\\sqrt{2}}$$\n",
    "\n",
    "Then we get the probability by taking the magnitude and squaring \n",
    "\n",
    "$$ P(H) = \\left| \\frac{1}{\\sqrt{2}} \\right|^2 = \\frac{1}{2} $$\n",
    "\n",
    "Since all the probabilities of the coin landing on $\\ket{h}$ or $\\ket{t}$ must add to 1, for a biased or unbiased coin, it must be that $P(H) + P(T) = 1$. Let the probability of getting heads be $P$. This gives us a state of \n",
    "$$\n",
    "\\ket{\\psi} = \\begin{bmatrix} \\sqrt{P} \\\\ \\sqrt{1-P} \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    ">### Exercise 4.2\n",
    ">\n",
    ">Using the definition of the measurement probability, calculate the probability of measuring heads and the probability of measuring tails. Verify that these add to 1. \n",
    "\n",
    "\n",
    "\n",
    "For any quantum state, the probability of measuring it to be in the state that it is must be 1. For example, if the coin were heads up, and nothing happened to the coin, the probability of measuring heads would be 1. The probability of getting a tails would be 0. This can be verified by working out the probability of measuring tails. The probability of measuring tails $P(T)$ is still given by the same equation \n",
    "\n",
    "$$ P(T) = |\\braket{T|\\psi}|^2 $$ \n",
    "\n",
    "where the coin is in the state $\\ket{\\psi}$ = $\\ket{h}$. \n",
    "\n",
    "$$  \n",
    "\\left| \\begin{bmatrix} 0 & 1 \\end{bmatrix} \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} \\right|^2 \n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\left| (0 \\times 1) + (1 \\times 0) \\right|^2 = 0 \n",
    "$$\n",
    "\n",
    "\n",
    "On the other hand, the probability of measuring a heads is 1. Whilst this result may seem obvious, it is worth emphasising that for any quantum state, the probability of measuring it in that state should be 1 (neglecting measurement error). This leaves us the important result\n",
    "\n",
    "$$ |\\braket{\\psi|\\psi}|^2 = 1 $$\n",
    "\n",
    "Another way of thinking about this is that for any quantum system, the probabilities of finding it in each of its states must add up to 1. \n",
    "\n",
    "> $ \\braket{\\psi|\\psi} = 1 $ must hold for any quantum state. \n",
    "\n",
    "This simplifies a lot of the maths. \n",
    "\n",
    "## 4.3 Operators: A trip to the casino \n",
    "\n",
    "### 4.3.1 What is an operator?\n",
    "\n",
    "An operator is a mathematical object that acts on a ket and returns a new ket. Operators are matrices that allow us to process quantum states. This is how we do quantum computing. \n",
    "\n",
    "Our operators are denoted by a capital letter, such as  $\\hat{O}$. They act on a quantum state $\\ket{\\psi}$ to return a new state $\\ket{\\psi'}$ as \n",
    "\n",
    "$$O\\ket{\\psi} = \\ket{\\psi'}$$\n",
    "\n",
    "This is just a matrix-vector product. \n",
    "\n",
    "\n",
    "\n",
    "In gambling, the outcome of some event results in the gambler winning or losing money. Imagine a very simple game where everytime you roll a heads you win $1, every time you roll a tails, you lose $1. \n",
    "\n",
    "We can define an operator, let's call it $Z$ that encodes the winnings and loses for each coin toss. \n",
    "\n",
    "If we roll a heads $\\ket{h}$ we should get +1, so we can encode that as \n",
    "\n",
    "$$\n",
    "Z\\ket{h} = +1 \\ket{h}\n",
    "$$\n",
    "\n",
    "Where the coefficient +1 is the winnings and the final state $\\ket{h}$ is what we end up with. \n",
    "\n",
    "Similarly for tails we lose a dollar so \n",
    "\n",
    "$$\n",
    "Z\\ket{t} = -1 \\ket{t}\n",
    "$$\n",
    "\n",
    "Using the vector representation of $\\ket{h}, \\ket{t}$ we can write the matrix $Z$\n",
    "\n",
    "$$ Z = \\begin{bmatrix} 1 & 0 \\\\ 0 & -1 \\end{bmatrix} $$\n",
    "\n",
    "It turns out $Z$ is an important quantum logic gate!\n",
    "\n",
    "\n",
    "We can invent another operator to perform the coin flip, we will call $H$  can be represented as \n",
    "\n",
    "$$\n",
    "\\hat{H} =  \\frac{1}{\\sqrt{2}} \\begin{bmatrix} 1 & 1 \\\\ 1 & -1 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    ">### Exercise 4.3 Flip the coin \n",
    ">\n",
    ">By applying the flip operator to a coin that is heads up, show that it gives us the superposition state. \n",
    ">\n",
    ">Hint: compute the matrix-vector product of $H\\ket{h}$. \n",
    ">\n",
    "> Bonus question: what would you get if you did the same with the coin starting tails up?\n",
    "\n",
    "## 4.4 What do we expect to get?\n",
    "\n",
    "In life there are many processes where we want to predict something. For instance, a farmer would want to know how good their next harvest would be, or a stockbroker would want to know whether or not a stock is going to go up or down in price. In those cases, the farmer is not interested in the probability of getting an exact crop yeild, but wants to know what yeild they should expect. Quantum mechanics allows us to caluate these expectation values.\n",
    "\n",
    "### 4.4.1 Classical probability \n",
    "\n",
    "What would we expect to get from our coin gambling example? \n",
    "\n",
    "We know that half the time we will get $1, and half the time we will lose $1. \n",
    "\n",
    "So our expected winnings, $\\braket{W}$ would be\n",
    "$$\n",
    "\\braket{W} = \\frac{1}{2} \\times 1 + \\frac{1}{2} \\times -1 \n",
    "=0\n",
    "$$\n",
    "\n",
    "We win as much as we lose, so we'd expect to get nothing. \n",
    "\n",
    "More generally we can write the expectation value in terms of the value of each outcome and the probability \n",
    "\n",
    "$$ \\braket{W} = \\sum_{i = 0}^{N-1} X_i \\times P(i) $$\n",
    "\n",
    "Where $X_i$ is the outcome for event $i$ with probability $P(i)$ . \n",
    "\n",
    " \n",
    ">### Exercise 4.4 Expectation value\n",
    ">\n",
    ">For this question, we're graduating from a coin to a dice. Let's call $N$ the number on a dice. Work out the expectation value by working out the number on each dice multiplied by the probability of rolling that number. \n",
    "\n",
    "### 4.4.2 A quantum description of probability \n",
    "\n",
    "So far this description of probability is entirely classical, even the use of angled brackets! A quantum description is more elegant. A perceptive reader might have noticed the similarities between the probability\n",
    "\n",
    "$$ \\braket{W} = \\sum_{i = 0}^{N-1} X_i \\times P(i) $$\n",
    "\n",
    "And the state vector\n",
    "\n",
    "$$\n",
    "\\ket{\\psi} = \\sum_{i = 0}^{N-1} c_i \\ket{i}\n",
    "$$ \n",
    "\n",
    "We can even get $P(i) = |c_i|^2$ so perhaps we can express the expectation value in terms of the state vector and something that gives us the outcome for each state,$X$. \n",
    "\n",
    "The previous example with the $1 gain/loss coin can be repeated with some quantum sauce. Recall the operator $Z$ that gave us the win/loss for heads and tails. We would like to work out the expected earnings. We know that we can get the amount earned $X_i$\n",
    "\n",
    "$$ X_i (\\ket{i}) = Z\\ket{i}$$\n",
    "\n",
    "Where $i$ can either be $H$ or $T$. \n",
    "\n",
    "And we can get the probability of getting $i$ from $\\braket{i|\\psi}$.\n",
    "\n",
    "Adding up all the probabilities gives us the important result\n",
    "$$\n",
    "\\braket{Z} = \\braket{\\psi|Z|\\psi}\n",
    "$$\n",
    "\n",
    "We have defined the expectation value of the operator $Z$. Assuming our coin is unbiased, it has the general superposition state. We can then compute the expectation value as\n",
    "\n",
    "$$\n",
    "\\frac{1}{\\sqrt{2}} \\begin{bmatrix} 1 & 1 \\end{bmatrix} \\begin{bmatrix} 1 & 0 \\\\ 0 & -1 \\end{bmatrix} \\frac{1}{\\sqrt{2}} \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}\n",
    "$$\n",
    "$$\n",
    "= \\frac{1}{2}\\begin{bmatrix} 1 & 1 \\end{bmatrix} \\begin{bmatrix} 1 \\\\ -1 \\end{bmatrix}\n",
    "$$\n",
    "$$ = \\frac{1}{2} ( 1 - 1) = 0 $$ \n",
    "\n",
    "## Chapter 4 Summary \n",
    "\n",
    "- Quantum states can be represented by column vectors \n",
    "- We can separate out a quantum state into orthogonal components \n",
    "- The number in front of the component is the probability amplitude\n",
    "- The probability of measuring a quantum system in a given state is given by the square of the modulus of the inner product\n",
    "- The inner product of a quantum state with itself always has magnitude 1\n",
    "- Operators transform quantum states and are represented by matrices\n",
    "- The expectation value for any operator, $\\hat{O}$  is given by $\\braket{O} = \\braket{\\psi|\\hat{O}|\\psi}$\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5 (default, Sep  3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
